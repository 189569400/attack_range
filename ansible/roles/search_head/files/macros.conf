#####################
## Boolean
#####################

## str_to_bool
[str_to_bool(1)]
args       = field
definition = `str_to_bool($field$,$field$)`

[str_to_bool_meval(1)]
args       = field
definition = `str_to_bool_meval($field$,$field$)`

[str_to_bool(2)]
args       = inField,outField
definition = eval `str_to_bool_meval($inField$,$outField$)`

[str_to_bool_meval(2)]
args       = inField,outField
definition = "$outField$"=case(match('$inField$', "1|[Tt]|[Tt][Rr][Uu][Ee]"),"true",match('$inField$', "0|[Ff]|[Ff][Aa][Ll][Ss][Ee]"),"false",1=1,'$inField$')

## tag2field
[tag2field(1)]
args       = field
definition = eval "is_$field$"=if(tag=="$field$","true","false")

[tag2field_requires(1)]
args       = field
definition = eval "requires_$field$"=if(tag=="requires_$field$","true","false")

[tag2field_should(1)]
args       = field
definition = eval "should_$field$"=if(tag=="should_$field$","true","false")


#####################
## Charting
#####################
[autopause]
definition = 120

[round(1)]
args       = field
definition = `round("$field$",2)`

[round(2)]
args       = field,precision
definition = `round("$field$","$field$",$precision$)`

[round(3)]
args       = inField,outField,precision
definition = eval "$outField$"=round('$inField$',$precision$)
errormsg   = precision (arg3) must be an integer greater than zero
iseval     = 0
validation = isint(precision) AND precision>0

[stats2chart(1)]
args       = str_field
definition = eval temp="" | chart useother=`useother` first(count) over temp by $str_field$ | rename temp as count

[useother]
definition = true

[wrap(2)]
args       = field,length
definition = rex field="$field$" max_match=0 "(?<$field$>.{1,$length$})"
errormsg   = length (arg2) must be an integer greater than zero
iseval     = 0
validation = isint(length) AND length>0


#####################
## Date/Time
#####################

## create simple date field
[get_date(1)]
args       = field
definition = eval date='$field$' | `ctime(date,"%m-%d-%Y")`

## convert epoch time to string
[ctime(1)]
args       = field
definition = `ctime($field$,"%m/%d/%Y %H:%M:%S")`

## convert epoch time to string w/ format
[ctime(2)]
args       = field,format
definition = convert timeformat="$format$" ctime($field$)

[ctime(3)]
args       = inField,outField,format
definition = `ctime($inField$,"$format$")` as $outField$

## convert string to epoch time
[mktime(1)]
args       = field
definition = `mktime($field$,"%m/%d/%Y %H:%M:%S")`

## convert string w/ format to epoch time
[mktime(2)]
args       = field,format
definition = convert timeformat="$format$" mktime($field$)

[mktime(3)]
args       = inField,outField,format
definition = `mktime($inField$,"$format$")` as $outField$

## format epoch time
[uitime(1)]
args       = field
definition = `uitime($field$,"%m/%d/%Y %H:%M:%S")`

## format epoch time w/ format
[uitime(2)]
args       = field,format
definition = fieldformat "$field$"=strftime('$field$', "$format$")

## convert uptime (# secs) to string
[uptime2string(2)]
args       = inField,outField
definition = eval days_dec='$inField$'/86400 | eval days=floor(days_dec) | eval hours_dec=('$inField$'/3600)-(days*24) | eval hours=floor(hours_dec) | eval minutes_dec=('$inField$'/60)-(days*1440)-(hours*60) | eval minutes=floor(minutes_dec) | eval "$outField$"=case(days==1,days." day, ",days>0,days." days, ",1==1,"").case(hours=1,hours." hour, ",hours>0,hours." hours, ",1=1,"").case(minutes=1,minutes." minute",minutes>0,minutes." minutes",1==1,"").case('$inField$'==1,'$inField$'." second",'$inField$'>=0 AND '$inField$'<60,replace('$inField$',"^(\d+(\.\d)?).*$","\1")." seconds",days=0 AND hours=0 AND ('$inField$'%60)=1,", ".ceil('$inField$'%60)." second",days=0 AND hours=0 AND ('$inField$'%60)>0,", ".ceil('$inField$'%60)." seconds",1=1,"") | eval "$outField$"=rtrim(rtrim('$outField$'), ",") | fields - days,hours,minutes

[timeDiff]
definition = `timeDiff(_time)`

[hourDiff]
definition = `hourDiff(_time)`

[dayDiff]
definition = `dayDiff(_time)`

[timeDiff(1)]
args       = field
definition = eval timeDiff=(time()-'$field$')

[hourDiff(1)]
args       = field
definition = eval hourDiff=((time()-'$field$')/3600)

[dayDiff(1)]
args       = field
definition = eval dayDiff=((time()-'$field$')/86400)

## Get events based on age in hours
[hoursago(2)]
args       = num, comparator
definition = `hourDiff` | search hourDiff$comparator$$num$

## default to events less than N hours ago
[hoursago(1)]
args       = num
definition = `hoursago($num$,"<")`

## Get events based on age in days
[daysago(2)]
args       = num, comparator
definition = `dayDiff` | search dayDiff$comparator$$num$

## default to events less than N days ago
[daysago(1)]
args       = num
definition = `daysago($num$,"<")`

## Make a timestamp from a time field with unknown format.
#  For use in converting TimeRangePicker values $search.timeRange.earliest$
#  and $search.timeRange.latest$ to timestamps if they are specified as relative
#  time modifiers.
#
# Breakdown:
# 1. If fieldIn == null(), the empty string, or whitespace, yield the value of time()
# 2. If fieldIn begins with a digit, yield the digit (assumed to be a timestamp or 0).
# 3. If fieldIn is a relative timestamp beginning with one of @, +, -, yield the converted value.
#
# Real-time qualifiers are not supported as these cannot be easily converted.
# Also, it doesn't appear to be possible to match using $ to anchor the end
# of a regex in these macros, since the $ is regarded as part of a variable expansion.
#
[make_ts_field(2)]
args       = fieldIn, fieldOut
definition = eval "$fieldOut$"=case(match('$fieldIn$', "^\d"), tostring('$fieldIn$'),  match('$fieldIn$', "^([@\+-]){1}"), relative_time(time(), '$fieldIn$'),  true(), time())

[make_ts_value(2)]
args       = value, fieldOut
definition = eval "$fieldOut$"=case(match("$value$", "^\d"), tostring("$value$"),  match("$value$", "^([@\+-]){1}"), relative_time(time(), "$value$"),  true(), time())

## Make the earliest and latest times that would capture the previous time-range
#  This is useful when you want to get historical information in order to
#  determine if information within a given window is higher or lower than
#  the previous window of the same size. For example, an earliest and
#  latest time range of -24h@h and now will produce a time-range of
#  -48h@h to -24h@h. The returned contents will be  a search that can be
#  used in a tstats where clause.
#
#  Breakdown:
#  1.  Make sure the search returns one row (with makeresults)
#  2.  Convert the earliest time to epoch
#  3.  Convert the latest time to epoch
#  4a. Get the size of the time-range (the difference between the earliest and latest)
#  4b. Define the latest time (previous earliest unless result is negative; then 0)
#  4c. Define the earliest time (subtract 4a from earliest unless it results in negative; then 0 earliest-time_span_diff)
#  4d. Make the search statement for the where clause
#  5.  Strip off unnecessary fields
#
[make_previous_time_range(2)]
args       = earliest, latest
definition = makeresults | `make_ts_value($earliest$,earliest)` | `make_ts_value($latest$,latest)` | eval time_span_diff=latest-earliest,latest=if(round(earliest)<0,0,round(earliest)),earliest=if(round(earliest-time_span_diff)<0,0,round(earliest-time_span_diff)),search="earliest=".earliest." latest=".latest | table search

## Macro for converting TimeRangePicker values to a "between X and Y days ago" format,
#  for use when using trackers which have a firstTime, lastTime value.
[tracker_timerange_by_field(4)]
args       = begin, end, firstTime, lastTime
definition = `make_ts_field($begin$, earliestQual)` | `make_ts_field($end$, latestQual)` | where ('$lastTime$'>earliestQual AND '$firstTime$'<latestQual) | fields - earliestQual, latestQual

[tracker_timerange_by_value(4)]
args       = begin, end, firstTime, lastTime
definition = `make_ts_value($begin$, earliestQual)` | `make_ts_value($end$, latestQual)` | where ('$lastTime$'>earliestQual AND '$firstTime$'<latestQual) | fields - earliestQual, latestQual

# Same as previous, just shortened to use the convention firstTime, lastTime
# for field names.
[tracker_timerange_by_field(2)]
args       = begin, end
definition = `tracker_timerange_by_field($begin$, $end$, firstTime, lastTime)`

[tracker_timerange_by_value(2)]
args       = begin, end
definition = `tracker_timerange_by_value($begin$, $end$, firstTime, lastTime)`

## Macro for converting TimeRangePicker values to a filter suitable for inputlookup's where clause
[tracker_trp]
definition = `tracker_trp(firstTime,lastTime)`

[tracker_trp(2)]
args       = begin, end
definition = [| makeresults | addinfo | eval search="$begin$>=".if(isnotnull(info_min_time),info_min_time,0).if(isnull(info_max_time) OR info_max_time="+Infinity",""," AND $end$<=".info_max_time) | return $search]

## Macro for setting time given an offset
[set_time]
definition = `set_time("-0s")`

[set_time(1)]
args       = qual
definition = eval _time=relative_time(time(),"$qual$")

[time_subsearch(2)]
args       = earliest,latest
definition = makeresults | eval search="_time>".floor(relative_time(time(),"$earliest$"))." _time<".floor(relative_time(time(),"$latest$")) | table search


#####################
## Event ID
#####################

## UPDATING EVENT ID REQUIRES:
## 1. Incident Review migration of existing event_id's
## 2. Adjusting any datamodels which calculate event_id explicitly
## 3. Updating parse_event_id macro
## 4. Update parsing for Incident Review "View original event" hyperlink
## 5. Check/Update FIPS Compliance in deploy_fips_compliant_settings.py

## Select the hash algorithm to use. This macro is set at setup time depending
## on the value of SPLUNK_FIPS in splunk-launch.conf. If SPLUNK_FIPS=1,
## SHA1 is the preferred algorithm and this will be reset accordingly.
[hash_alg]
definition = md5

## Get the indexer GUID from the _bkt field (SOLNESS-5985)
[get_indexer_guid]
definition = rex field=_bkt ".*~(?<indexer_guid>.+)"

[get_indexer_guid_meval]
definition = indexer_guid=replace(_bkt,".*~(.+)","\1")

## Create the "event_hash" field as the hash of the "_raw" field (event text)
[get_event_hash]
definition = eval `get_event_hash_meval`

[get_event_hash_meval]
definition = event_hash=`hash_alg`(_time._raw)

## Create the unique event identifier ("event_id") as a combination of "splunk_server","index", and "event_hash" fields
## Makes an event_id compatible with real-time (no _cd)
[get_event_id]
definition = eval `get_event_id_meval`

[get_event_id_meval]
definition = `get_indexer_guid_meval`,`get_event_hash_meval`,event_id=indexer_guid."@@".index."@@".event_hash

## Dissect the unique event identifier ("event_id") into "orig_splunk_server", "orig_index", "orig_event_hash"
## Parses an event_id compatible with real-time (no _cd)
## See also props.conf "REPORT-orig_splunk_server-orig_index-orig_event_hash_for_notable = orig_splunk_server-orig_index-orig_event_hash_for_notable"
[parse_event_id(1)]
args       = event_id
definition = rex field="$event_id$" "(?<orig_indexer_guid>.*?)\@\@(?<orig_index>.*?)\@\@(?<orig_event_hash>.*)"


##########################
## Key Security Indicators
##########################

[xs_default_direction_concepts]
definition = "decreasing,unchanged,increasing"

[xs_default_magnitude_concepts]
definition = "minimal,low,medium,high,extreme"

[xs_default_change_concepts]
definition = "minimally,slightly,moderately,greatly,extremely"

# Note that "convert" expected to be a string, not a field name.
[convert_ksi_nonnumeric(4)]
args       = infield,outfield,convert,value
definition = eval "$outfield$"=if("$convert$"=="true" and !isnum('$infield$'), "$value$", '$infield$')
errormsg   = value (arg4) must be a number
iseval     = 0
validation = isnum(value)

[get_ksi_fields(2)]
# Breakdown:
# 1. Convert curr to numeric value if requested.
# 2. Convert prev to numeric value if requested.
# 3. Get the direction "increasing", "decreasing", "unchanged", "undefined"
#    The last value will only be returned if numeric conversion was skipped.
# 4. Get the percent change. Percent change is passed to "xsFindBestConcept",
#    so MUST have a numeric value. If the customer wants to use "undefined" as
#    a percentage change value when data is missing, this must be handled in
#    the KSI search itself.
#    NOTE: "delta" is used as the field name instead of the more descriptive "percent_change".
#    for consistency with existing practice.
args       = curr,prev
definition = `get_ksi_fields($curr$,$prev$,"true",0)`

[get_ksi_fields(4)]
args       = curr,prev,convert,convert_to
definition = `convert_ksi_nonnumeric($curr$,$curr$,"$convert$",$convert_to$)` | `convert_ksi_nonnumeric($prev$,$prev$,"$convert$",$convert_to$)` | `get_ksi_direction($curr$,$prev$,"direction")` | `get_ksi_percent_change($curr$,$prev$,"delta")`

[get_ksi_direction(3)]
# Breakdown:
# 1. If curr or prev are still null, then we have requested no handling for non-numeric.
#    values. Produce "undefined" output.
# 2. If curr and prev are now numeric, output one of "increasing", "decreasing", "unchanged"
args       = curr,prev,outfield
definition = eval "$outfield$"=if(!(isnum('$curr$') and isnum('$prev$')), "undefined", if('$curr$' > '$prev$', "increasing", if('$curr$' < '$prev$', "decreasing", "unchanged")))

[get_ksi_percent_change(3)]
args       = curr,prev,outfield
definition = `get_ksi_percent_change($curr$,$prev$,$outfield$,"true")`

[get_ksi_percent_change(4)]
# This macro must yield a numeric value for passing to xsFindBestConcept.
# Breakdown:
# 1. If conversion is not chosen and either value is null ==> "undefined".
# 2. If curr or prev are equivalent ==> 0
# 3. If curr or prev are 0 or non-numeric ==> sign of the other value * 100
# 4. If both curr and prev are numeric and non-zero ==> calculate exact percent change.
# 5. Otherwise 0.
# 6. Round to two decimal places.
args       = curr,prev,outfield,convert
definition = eval "$outfield$"=case((isnull('$curr$') or isnull('$prev$')) and convert!="true", "undefined", '$curr$'=='$prev$', 0, isnum('$curr$') and '$curr$'!=0 and ('$prev$'==0 or !isnum('$prev$')), '$curr$'/abs('$curr$') * 100.00, isnum('$prev$') and '$prev$'!=0 and ('$curr$'==0 or !isnum('$curr$')), (0-'$prev$')/abs('$prev$') * 100, isnum('$curr$') and isnum('$prev$') and '$prev$'!=0 and '$curr$'!=0, ('$curr$'-'$prev$')/'$prev$' * 100.0, 1==1, 0) | eval "$outfield$"=if(isnum('$outfield$'),round('$outfield$', 2), '$outfield$')


#####################
## Math
#####################
[bytes2kbytes(1)]
args       = field
definition = `bytes2kbytes($field$,$field$)`

[bytes2kbytes(2)]
args       = inField,outField
definition = eval "$outField$"='$inField$'/1024

[bytes2mbytes(1)]
args       = field
definition = `bytes2mbytes($field$,$field$)`

[bytes2mbytes(2)]
args       = inField,outField
definition = eval "$outField$"='$inField$'/1048576

[bytes2gbytes(1)]
args       = field
definition = `bytes2gbytes($field$,$field$)`

[bytes2gbytes(2)]
args       = inField,outField
definition = eval "$outField$"='$inField$'/1073741824

## Globe distance
[globedistance(5)]
args = lat1,long1,lat2,long2,units
definition = `globedistance("distance",$lat1$,$long1$,$lat2$,$long2$,$units$,2)`

[globedistance(7)]
# The "precision" argument is numeric therefore unquoted.
args = outfield,lat1,long1,lat2,long2,units,precision
definition = eval lat1_r='$lat1$'*pi()/180 | eval lat2_r='$lat2$'*pi()/180 | eval delta=('$long2$'-'$long1$')*pi()/180 | eval R=if('$units$'="m",3959, 6372.8) | eval "$outfield$"=R*acos(sin(lat1_r)*sin(lat2_r) + cos(lat1_r) * cos(lat2_r) * cos(delta)) | eval "$outfield$"=round('$outfield$', $precision$) | fields - lat1_r,lat2_r,long1_r,long2_r,R,delta

## Standard deviation
[standard_deviations]
definition = inputlookup append=T standard_deviations

[stdev(2)]
args       = intField,countField
definition = eventstats min($intField$) as min_$intField$,max($intField$) as max_$intField$,sum($countField$) as total | eventstats sum(eval($intField$*$countField$/total)) as mean_$intField$ | eventstats sum(eval(pow($intField$-mean_$intField$,2)*$countField$)) as sumsq | eval stdev=sqrt(sumsq/(total-1)) | `get_stdev_index($intField$)` | eval stdev=if(isnull(stdev),0,stdev)

## We can't single quote $Z$ at this time because of how it is invoked
## Currently we are invoking this with a negation operator
## | `stdev_desired_result(standard_deviation,mean_bytes,"gt_bytes")` | `stdev_desired_result(-standard_deviation,mean_bytes,"lt_bytes")`
[stdev_desired_result(3)]
args       = Z,mean,outField
definition = eval "$outField$"=($Z$*stdev)+'$mean$'

[get_stdev_index(1)]
args       = intField
definition = eval Z=(('$intField$'-'mean_$intField$')/stdev)

[get_delta]
args       =
definition = `get_delta(current_count,historical_count)`

[get_delta(2)]
args       = field1,field2
definition = eval "$field1$"=if(isnum('$field1$'),'$field1$',0) | eval "$field2$"=if(isnum('$field2$'),'$field2$',0) | eval delta='$field1$'-'$field2$'


#############################
## Multivalued field handling
#############################

## Filters a value from a multi-valued field UNLESS it is the only value.
[mvfilter_value(2)]
args       = field, value
definition = eval "$field$"=if(mvcount('$field$')>1 AND '$field$'="$value$", mvfilter('$field$'!="$value$"), '$field$')

## Filters a field-value from a multi-valued field UNLESS it is the only value.
[mvfilter_field(2)]
args       = field, filter_field
definition = eval `mvfilter_field_meval($field$,$filter_field$)`

[mvfilter_field_meval(2)]
args       = field, filter_field
definition = "$field$"=if(mvcount('$filter_field$')=1 AND mvcount('$field$')>1 AND '$field$'='$filter_field$',split(ltrim(replace("|".mvjoin('$field$',"|"),"\|".'$filter_field$',""),"|"), "|"),'$field$')

## create a mv field from a sv field w/ default separator
[makemv(1)]
args       = field
definition = `makemv($field$,"|")`

[makemv_meval(1)]
args       = field
definition = `makemv_meval($field$,"|")`

## create a mv field from a sv field w/ user defined separator
[makemv(2)]
args       = field, sep
definition = eval "$field$"=split('$field$',"$sep$")

[makemv_meval(2)]
args       = field, sep
definition = "$field$"=split('$field$',"$sep$")

## create a sv field from a mv field w/ default separator
[makesv(1)]
args       = field
definition = `makesv($field$,"|")`

## create a sv field from a mv field w/ user defined separator
[makesv(2)]
args       = field, sep
definition = eval "$field$"=mvjoin('$field$',"$sep$")

## appends the values of field2 to field1
[mvappend_field(2)]
args       = field1, field2
definition = eval "$field1$"=mvdedup(mvappend('$field1$',NULL,'$field2$'))

[mvappend_field_meval(2)]
args       = field1, field2
definition = "$field1$"=mvdedup(mvappend('$field1$',NULL,'$field2$'))

## appends value to field
[mvappend_value(2)]
args       = field, value
definition = eval "$field$"=mvdedup(mvappend('$field$',"$value$",NULL))

## appends value to field if bool==true
[mvappend_bool(3)]
args       = field, value, bool
definition = eval "$field$"=if(match('$bool$', "1|[Tt]|[Tt][Rr][Uu][Ee]"),mvdedup(mvappend('$field$',"$value$",NULL)),'$field$')

[mvappend_bool_meval(3)]
args       = field, value, bool
definition = "$field$"=if('$bool$'=="true",mvdedup(mvappend('$field$',"$value$",NULL)),'$field$')

## appends value to field if is_value==true
## i.e. appends "foo" to "bar" if "is_foo==true"
[mvappend_is(2)]
args       = field, value
definition = `mvappend_bool($field$,$value$,"is_$value$")`

[mvappend_is_meval(2)]
args       = field, value
definition = `mvappend_bool_meval($field$,$value$,"is_$value$")`

## appends should_value to field if should_value==true
## i.e. appends "should_foo" to "bar" if "should_foo==true"
[mvappend_should(2)]
args       = field, value
definition = `mvappend_bool($field$,should_$value$,"should_$value$")`

[mvappend_should_meval(2)]
args       = field, value
definition = `mvappend_bool_meval($field$,should_$value$,"should_$value$")`

## appends requires_value to field if requires_value==true
## i.e. appends "requires_foo" to "bar" if "requires_foo==true"
[mvappend_requires(2)]
args       = field, value
definition = `mvappend_bool($field$,requires_$value$,"requires_$value$")`

[mvappend_requires_meval(2)]
args       = field, value
definition = `mvappend_bool_meval($field$,requires_$value$,"requires_$value$")`

## mvdedup
## takes a multivalued field as input and creates a multivalued field containing only unique input values as output
[mvdedup(1)]
args       = input
definition = `mvdedup($input$,$input$)`

[mvdedup(2)]
args       = input, output
definition = eval "$output$"=mvdedup('$input$')

## mvtruncate
[mvtruncate(1)]
args       = input
definition = `mvtruncate($input$,$input$,10)`

[mvtruncate(3)]
args       = input, output, count
definition = eval "$output$"=if(mvcount('$input$')>$count$,mvappend(mvindex('$input$',0,$count$-1),NULL,"...truncated..."),'$input$')
errormsg   = count (arg3) must be a number
validation = isnum(count)


#####################
## Integers
#####################

## 1.  Trim a number x (where x==11) of leading characters from _raw
## 1a. This is what the offset param for luhn_lookup.py does
## 2.  Pull out integer sequences based on regular expression
## 2a. Using \s and - as default separators
## 2b. For additional separators add additional "(?:\d+[<sep>]*){14,})" to the list
## 2c. {14,} defines minStrength y (where y==14)
[get_integer_seq]
definition = eval sub_raw=substr(_raw,11) | rex field=sub_raw max_match=10 "(?<integer_seq>(?:\d+[\s]*){14,}|(?:\d+[-]*){14,})"


#####################
## IP Address Utility
#####################

[ipv4_cidr_regex]
definition = "^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}/(\d|[12]\d|3[012])$"


#####################
## Per Panel Filtering
#####################

## Per Panel Filter Breakdown
## 1 - Per Panel Filter Lookup
## 2 - Remove whitelisted entries
## 3 - Remove all ppf fields except (ppf_filter)
[per_panel_filter(2)]
args       = lookup,inputFields
definition = `per_panel_filter("$lookup$","$inputFields$",time())`

[per_panel_filter(3)]
args       = lookup,inputFields,compareTime
definition = `per_panel_filter_lookup("$lookup$","$inputFields$",$compareTime$)` | search NOT ppf_filter=whitelist | fields - ppf_lookup_type,ppf_st,ppf_et,temp_time | eval ppf_cell=if(isnull(ppf_filter),mvappend("", $inputFields$),mvappend(ppf_filter,$inputFields$))

## Per Panel Filter Subsearch Breakdown
## 1 - Get representative inputFields values by bring in ppf table using inputlookup
## 2 - Remove all other fields
## 3 - Deduplicate
## 4 - Perform per_panel_filter_lookup
## 5 - Remove all blacklisted entries
## 6 - Remove all other fields
## 7 - Format results
[ppf_subsearch(3)]
args       = lookup,inputFields,compareTime
definition = inputlookup append=t $lookup$ | table $inputFields$ | dedup $inputFields$ | `per_panel_filter_lookup("$lookup$","$inputFields$",$compareTime$)` | search ppf_filter=whitelist | table $inputFields$ | format | table search

## Per Panel Filter Datamodel Subsearch Breakdown
## 1 - Get representative inputFields values by bring in ppf table using inputlookup
## 2 - Remove all other fields
## 3 - Deduplicate
## 4 - Perform per_panel_filter_lookup
## 5 - Remove all blacklisted entries
## 6 - Remove all other fields
## 7 - Add object lineage to field names
## 8 - Format results
[ppf_subsearch_dm(4)]
args       = lookup,inputFields,compareTime,object
definition = inputlookup append=t $lookup$ | table $inputFields$ | dedup $inputFields$ | `per_panel_filter_lookup("$lookup$","$inputFields$",$compareTime$)` | search ppf_filter=whitelist | table $inputFields$ | rename * as $object$.* | format | table search

## Per Panel Filter Lookup Breakdown
## 1a - Set _time as the current time
## 1b - Set lookup type to blacklist
## 2  - Perform OUTPUT lookup for blacklisted entries
## 3  - Set/Unset "ppf_filter" based on filter=blacklist and time bounds
## 4  - Reset ppf_st/ppf_et by removing these fields
## 5  - Set lookup type to whitelist
## 6  - Perform OUTPUTNEW lookup for whitelisted entries
## 6a - OUTPUTNEW is important here!  This basically ignores entries that previously matched a blacklist
## 7  - Set/Unset "ppf_filter" based on filter=whitelist and time bounds
[per_panel_filter_lookup(3)]
args       = lookup,inputFields,compareTime
definition = eval temp_time=time(),ppf_lookup_type="blacklist" | lookup update=true event_time_field=temp_time $lookup$ $inputFields$,filter as ppf_lookup_type OUTPUT start_time as ppf_st,end_time as ppf_et,filter as ppf_filter | eval ppf_filter=if(ppf_filter="blacklist" AND ppf_st<$compareTime$ AND (ppf_et>$compareTime$ OR isnull(ppf_et)),ppf_filter,null()) | fields - ppf_st,ppf_et | eval ppf_lookup_type="whitelist" | lookup update=true event_time_field=temp_time $lookup$ $inputFields$,filter as ppf_lookup_type OUTPUTNEW start_time as ppf_st,end_time as ppf_et,filter as ppf_filter | eval ppf_filter=if(ppf_filter="blacklist" OR (ppf_filter="whitelist" AND ppf_st<$compareTime$ AND (ppf_et>$compareTime$ OR isnull(ppf_et))),ppf_filter,null())

[ppf_updates]
definition = eventtype=ppf_updates | fillnull value=unknown filter | fillnull value=edit action


#####################
## REST
#####################
[rest_handler_transactions]
definition = index=_internal sourcetype=*:rest_handler (Entering OR "completed successfully") | `get_namespace` | rex field=sourcetype "(?<handler>\w+):rest_handler" | rex "ACTION_(?<action>\w+)" | transaction handler,action startswith=Entering endswith="completed successfully" maxspan=30s maxpause=30s maxevents=2


#####################
## SHC
#####################
[host_equal_local]
definition = rest splunk_server=local count=0 /services/server/info | table serverName | rename serverName as host

## 1.  Search
## 1a. Local server events only
## 1b. Internal Index
## 1c. All conf.log events
## 1d. Configuration push/pull events
## 1e. For specified configuration
## 1f. Status Applied
[shc_replication_change(1)]
args       = config
definition = [| `host_equal_local`] index=_internal source=*conf.log (data.process="pullFrom" OR data.process="acceptPush") data.asset_uri{}="$config$" data.status="applied"


#####################
## Sorting
#####################
[sort_chart]
definition = `sort_chart(10)`

[sort_chart(1)]
args       = head
definition = addtotals fieldname=Total | eval Total=if(isnotnull(src_port),Total-src_port,Total) | eval Total=if(isnotnull(dest_port),Total-dest_port,Total) | sort $head$ - Total | fields - Total
errormsg   = head (arg1) must be an integer greater than zero
iseval     = 0
validation = isint(head) AND head>0

[sort_chart(2)]
args       = head, fields
definition = addtotals fieldname=Total $fields$ | sort $head$ - Total | fields - Total
errormsg   = head (arg1) must be an integer greater than zero
iseval     = 0
validation = isint(head) AND head>0


#####################
## Summary Indexing
#####################
[filter]
definition = NOT tag=filtered

[get_summary(2)]
args       = index,search_name
definition = index="$index$" search_name="$search_name$" `filter` | `makemv(orig_tag)` | `mvappend_field(tag,orig_tag)`

###### settags ######
## This macro has been deprecated
[settags_governance]
definition = (tag LIKE "%")

## This macro has beeen deprecated
[filtertags(1)]
args       = domain
definition = `filtertags("$domain$","tag")`
errormsg   = domain (arg1) must be one of: access, endpoint, or network
iseval     = 0
validation = domain="access" OR domain="endpoint" OR domain="network"

## This macro has beeen deprecated
[filtertags(2)]
args       = domain,outField
definition = eval "$outField$"=mvfilter(`settags_$domain$` OR `settags_governance`)
errormsg   = domain (arg1) must be one of: access, endpoint, or network
iseval     = 0
validation = domain="access" OR domain="endpoint" OR domain="network"

## This macro has beeen deprecated
[settags(1)]
args       = domain
definition = eval tag=mvfilter(`settags_$domain$` OR `settags_governance`) | rename tag as orig_tag
errormsg   = domain (arg1) must be one of: access, endpoint, or network
iseval     = 0
validation = domain="access" OR domain="endpoint" OR domain="network"


#####################
## Transformations
#####################

## lower
[lower(1)]
args       = field1
definition = eval "$field1$"=lower('$field1$')

## namespace
[get_namespace]
definition = lookup local=true sourcetype2namespace sourcetype OUTPUT namespace

###### sistats aggregrate renames ######

## min
[sistats_min_rename(2)]
args       = input, output
definition = eval "psrsvd_ct_$output$"=if(isnull('psrsvd_ct_$output$'),'psrsvd_ct_$input$','psrsvd_ct_$output$') | eval "psrsvd_nc_$output$"=if(isnull('psrsvd_nc_$output$'),'psrsvd_nc_$input$','psrsvd_nc_$output$') | eval "psrsvd_nn_$output$"=if(isnull('psrsvd_nn_$output$'),'psrsvd_nn_$input$','psrsvd_nn_$output$') | eval "psrsvd_sn_$output$"=if(isnull('psrsvd_sn_$output$'),'psrsvd_sn_$input$','psrsvd_sn_$output$') | eval "psrsvd_vt_$output$"=if(isnull('psrsvd_vt_$output$'),'psrsvd_vt_$input$','psrsvd_vt_$output$')

## max
[sistats_max_rename(2)]
args       = input, output
definition = eval "psrsvd_ct_$output$"=if(isnull('psrsvd_ct_$output$'),'psrsvd_ct_$input$','psrsvd_ct_$output$') | eval "psrsvd_nc_$output$"=if(isnull('psrsvd_nc_$output$'),'psrsvd_nc_$input$','psrsvd_nc_$output$') | eval "psrsvd_nx_$output$"=if(isnull('psrsvd_nx_$output$'),'psrsvd_nx_$input$','psrsvd_nx_$output$') | eval "psrsvd_sx_$output$"=if(isnull('psrsvd_sx_$output$'),'psrsvd_sx_$input$','psrsvd_sx_$output$') | eval "psrsvd_vt_$output$"=if(isnull('psrsvd_vt_$output$'),'psrsvd_vt_$input$','psrsvd_vt_$output$')

## values
[sistats_values_rename(2)]
args       = input, output
definition = eval "psrsvd_ct_$output$"=if(isnull('psrsvd_ct_$output$'),'psrsvd_ct_$input$','psrsvd_ct_$output$') | eval "psrsvd_nc_$output$"=if(isnull('psrsvd_nc_$output$'),'psrsvd_nc_$input$','psrsvd_nc_$output$') | eval "psrsvd_vm_$output$"=if(isnull('psrsvd_vm_$output$'),'psrsvd_vm_$input$','psrsvd_vm_$output$')

## transport_dest_port
[get_transport_dest_port]
args       =
definition = fillnull value=unknown transport | fillnull value=0 dest_port | eval transport_dest_port=transport."/".dest_port

[split_transport_dest_port(1)]
args       = field
definition =  rex field="$field$" "(?<transport>[^/]+)/(?<port>\d+)" | fillnull value=unknown transport | fillnull value=0 dest_port

## trim
[trim(1)]
args       = field
definition = eval "$field$"=trim('$field$'," ")

## truncate
[truncate(2)]
args       = field,length
definition = eval "$field$"=if(length('$field$')>$length$, substr('$field$', 0, $length$) + "...", '$field$')
errormsg   = length (arg2) must be an integer greater than or equal to zero
iseval     = 0
validation = isint(length) AND length>=0


#####################
## TSIDX
#####################
[tscollect(1)]
args       = namespace
definition = `tscollect("$namespace$","true","false")`

[tscollect(2)]
args       = namespace,squashcase
definition = `tscollect($namespace$,$squashcase$,"false")`

[tscollect(3)]
args       = namespace,squashcase,keepresults
definition = tscollect namespace=$namespace$ squashcase=$squashcase$ keepresults=$keepresults$
errormsg   = squashcase/keepresults (arg2/arg3) must be one of: true or false
iseval     = 0
validation = (squashcase="true" OR squashcase="false") AND (keepresults="true" OR keepresults="false")

[tstats]
definition = tstats prestats=true local=`tstats_local` `summariesonly`

[tstats_local]
definition = false

[summariesonly]
definition = summariesonly=`summariesonly_bool` allow_old_summaries=`allow_old_summaries_bool`

[summariesonly_bool]
definition = true

[allow_old_summaries_bool]
definition = true


#####################
## Users
#####################

## get_realname breakdown
## 1 - Lookup the users realname in user_realnames collection
## 2 - If the realname could not be found, use the username
[get_realname(1)]
args       = user
definition = lookup update=true user_realnames_lookup user as "$user$" OUTPUTNEW realname as "$user$_realname" | eval "$user$_realname"=if(isnull('$user$_realname'),'$user$','$user$_realname')


#####################
## SA-Utils internal
#####################
[script_error_msg_ignore]
definition = (match(script, "(streamfwd|splunk-(wmi\.path|MonitorNoHandle\.exe|winevtlog\.exe|netmon\.exe|perfmon\.exe|regmon\.exe|winprintmon\.exe|admon\.exe|powershell\.exe))") AND exit_status=1) OR (script LIKE "%instrumentation.py" AND exit_status=114)